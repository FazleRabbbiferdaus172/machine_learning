{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Adaline.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPMqZ6PGluNu4+1kSyFpePc",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/FazleRabbbiferdaus172/machine_learning/blob/master/Adaline.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fijz76fjLMzh",
        "colab_type": "text"
      },
      "source": [
        "#**Adaline**\n",
        "##Adaptive Linear Neuron\n",
        "###Updated based on a linear activation function "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I9H5X9lRU7Yb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "class AdalineGD(object):\n",
        "    \"\"\"Perceptron classifier.\n",
        "\n",
        "    Parameters\n",
        "    ------------\n",
        "    eta : float\n",
        "        Learning rate (between 0.0 and 1.0)\n",
        "    n_iter : int\n",
        "        Passes over the training dataset.\n",
        "    random_state : int\n",
        "        Random number generator seed for random weight initialization.\n",
        "\n",
        "    Attributes\n",
        "    -----------\n",
        "\n",
        "    w_ : 1d-array\n",
        "        Weights after fitting.\n",
        "    cost_ : list\n",
        "        Sum-of-squres cost function value in each epoch\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, eta = 0.01, n_iter = 50, random_state=1):\n",
        "        self.eta = eta\n",
        "        self.n_iter = n_iter\n",
        "        self.random_state = random_state\n",
        "\n",
        "    def fit(self, X, y):\n",
        "        \"\"\"Fit traning data.\n",
        "        \n",
        "        Parameters\n",
        "        -----------\n",
        "        X : {array-like}, shape = [n_samples, n_features]\n",
        "            Traning vectors, where n_samples is the number of samples and\n",
        "            n_features is the number of features.\n",
        "        y : array-like, shape = [n_samples]\n",
        "            Target values.\n",
        "        \n",
        "        Returns\n",
        "        ---------\n",
        "        self : object\n",
        "\n",
        "        \"\"\"\n",
        "\n",
        "        rgen = np.random.RandomState(self.random_state)\n",
        "        self.w_ = rgen.normal(loc=0.0, scale= 0.01, size=1 + X.shape[1])\n",
        "\n",
        "        self.cost_ = []\n",
        "\n",
        "        for _ in range(self.n_iter):\n",
        "            net_input = self.net_input(X)\n",
        "            output = self.activation(net_input)\n",
        "            errors = (y - output)\n",
        "            self.w_[1:] += self.eta * X.T.dot(errors) #calculates the gradient based on the whole training dataset  for the weights 1 to m\n",
        "            self.w_[0] += self.eta * errors.sum()   #calculates the gradient based on the whole training dataset for bias\n",
        "            cost = (error**2).sum() / 2.0\n",
        "            self.cost_.append(cost)\n",
        "        return self\n",
        "\n",
        "    def net_input(self, X):\n",
        "        \"\"\"Calculate net input\"\"\"\n",
        "        return np.dot(X, self.w_[1:]) + self.w_[0]\n",
        "\n",
        "    def activation(self, X):\n",
        "        \"\"\"Compute liner activation\"\"\"    \n",
        "        return X    # Activation method has no effect in the code since it is simply an identity function\n",
        "\n",
        "    def predict(self, X):\n",
        "        \"\"\"Return class label after unit step\"\"\"\n",
        "        return np.where(self.net_input(X) >= 0.0, 1, -1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eumPu2gZmXfn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}